{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW6 (20')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "Please submit your assignment as an HTML or PDF file.\n",
    "\n",
    "Print your name (First and Last) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brynna Garden\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here:\n",
    "print ('Brynna Garden')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "Import the `pandas`, `matplotlib.pyplot`, `numpy`, `scipy` libraries and assign them with proper nicknames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete this code section.\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write a function that output marginal summary statistics and missing values for continuous variable (10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Write the function with `def`** (6')\n",
    "- Given a vector of continuous measure, you are asked to write a function named `fn_marginal_continuous`.\n",
    "- The function has one parameter `input_vec` and outputs a list of summary measure and the number of missing values.\n",
    "- Check the missingness of the `input_vec` using `np.isnan()` or `pd.isna()` functions.\n",
    "    - In our first case, we will assume the `input_vec` is an numpy array with missing values marked with `np.nan`.\n",
    "- The list of summary measure can be either **(mean, std)** or **(median, q1, q3)** depending on the normality assumption.\n",
    "    - To determine the normality assumption, you can rely on the p-value of the Shapiro-Wilk test.\n",
    "    - Relevant functions can be found here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html \n",
    "    - If the p-value < 0.05, it is not normally distributed, otherwise, you can treat it as normally distributed.\n",
    "    - Think about what measure to report based on the normality assumption.\n",
    "    - Part of relevant functions can be found here: https://numpy.org/doc/2.0/reference/generated/numpy.nanmean.html\n",
    "- The return statement should include two components: `missing_num` and `output_ls` (your summmary measure).\n",
    "    - The missing numbers should be of type `int` instead of `np.int64`, and summary values should be of type `float` instead of `np.float64`.\n",
    "    - Round all your summary values such that they have no more than **3** digits after the decimals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your defined function in this code chunk only.\n",
    "#Writing the function with def with a function named fn_marginal_continuous \n",
    "def fn_marginal_continuous(input_vec):\n",
    "    missing = np.isnan(input_vec)\n",
    "    input_vec_clean = input_vec[~missing]\n",
    "    #Checking missingness\n",
    "    missing_num = np.sum(missing).astype(int)\n",
    "    #Removing missing values and checking normality assumption\n",
    "    stat, p_value = shapiro(input_vec_clean)\n",
    "    if p_value >= 0.05: \n",
    "        #For normally distributed \n",
    "        mean_val = float(np.round(np.mean(input_vec_clean), 3))\n",
    "        std_val = float (np.round(np.std(input_vec_clean), 3))\n",
    "        output_ls = [mean_val, std_val]\n",
    "    else:\n",
    "        #For not normally distributed \n",
    "        median_val = float(np.round(np.median(input_vec_clean), 3))\n",
    "        q1 = float(np.round(np.percentile(input_vec_clean, 25), 3))\n",
    "        q3 = float(np.round(np.percentile(input_vec_clean, 75), 3))\n",
    "        output_ls = [median_val, q1, q3]\n",
    "    return missing_num, output_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Test your function with the following different arguments:** (4') <br>\n",
    "For each scenario, please export the results as `missing_num_x`, `output_ls_x` and print them out separately.\n",
    "1. A standard normal random vector with a sample size of 100, named `input_vec_1`.\n",
    "2. A Chi-squared random vector with a degree of freedom 1 and a sample size of 100, named `input_vec_2`.\n",
    "3. Change the first element of `input_vec_1` as `np.nan` and create a new array named `input_vec_3`.\n",
    "    - Note that to create a copy of an numpy array, use `np.copy()` first.\n",
    "4. Change the last element of `input_vec_2` as `np.nan` and create a new array named `input_vec_4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[-0.07, 1.064]\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 1:\n",
    "#A standard normal random vector with a sample size of 100, named input_vec_1\n",
    "input_vec_1 = np.random.normal(loc=0, scale=1, size=100)\n",
    "missing_num_1, output_ls_1 = fn_marginal_continuous(input_vec_1)\n",
    "print(missing_num_1)\n",
    "print(output_ls_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.387, 0.045, 1.098]\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 2:\n",
    "#A Chi-squared random vector with a degree of freedom 1 and a sample size of 100, named input_vec_2\n",
    "input_vec_2 = np.random.chisquare(df=1, size=100)\n",
    "missing_num_2, output_ls_2 = fn_marginal_continuous(input_vec_2)\n",
    "print(missing_num_2)\n",
    "print(output_ls_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[-0.054, 1.057]\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 3:\n",
    "#Change the first element of input_vec_1 as np.nan and create a new array named input_vec_3\n",
    "input_vec_3 = np.copy(input_vec_1)\n",
    "input_vec_3 [0]= np.nan\n",
    "missing_num_3, output_ls_3 = fn_marginal_continuous(input_vec_3)\n",
    "print(missing_num_3)\n",
    "print(output_ls_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0.407, 0.047, 1.12]\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 4:\n",
    "#Change the last element of input_vec_2 as np.nan and create a new array named input_vec_4\n",
    "input_vec_4 = np.copy(input_vec_2)\n",
    "input_vec_4[-1] = np.nan\n",
    "missing_num_4, output_ls_4 = fn_marginal_continuous(input_vec_4)\n",
    "print(missing_num_4)\n",
    "print(output_ls_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a function that output marginal summary statistics and missing values for categorical variable (5')\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "**Write the function with `def`**\n",
    "- Given a column vector, you are asked to write a function named `fn_marginal_categorical`.\n",
    "- The function has one parameter named `input_vec` and outputs a list of summary measure and the number of missing values.\n",
    "- Check the missingness of the `input_vec` using `np.isnan()` or `pd.isna()` functions.\n",
    "    - In our second case, we will assume the `input_vec` is a column from a pandas DataFrame with missing values marked with `np.nan`.\n",
    "    - You can use both functions to identify missing values and yield the number of missingness.\n",
    "    - Use `pd.Series.value_counts()` function to obtain the frequency and proportion of `input_vec`, denoted as `tab_count` and `tab_percent`, respectively.\n",
    "    - Details can be found here: https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
    "    - For proportion, please use percentage (0-100%). You can ignore % when reporting.\n",
    "- The return statement should include two components: `missing_num` and `output_tab` (your summmary measure).\n",
    "    - For your `output_tab`, combine the count and proportion together using `pd.concat()`. Your `output_tab` should have three columns: variable name, count, and proportion.\n",
    "    - Details can be found here: https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "    - The missing numbers should be of type `int` instead of `np.int64`, and percentgae values should be of type `float` instead of `np.float64`.\n",
    "    - Round all your relevant summary values such that they have no more than **2** digits after the decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your defined function in this code chunk only.\n",
    "def fn_marginal_categorical(input_vec):\n",
    "    missing_num = int((pd.isna(input_vec)).sum())\n",
    "    #Removing missing values and checking normality assumption\n",
    "    clean_vec = input_vec[~pd.isna(input_vec)]\n",
    "    #Obtaining the frequency and proportion of input_vec, denoted as tab_count and tab_percent\n",
    "    tab_count = clean_vec.value_counts()\n",
    "    tab_percent = clean_vec.value_counts(normalize=True) * 100\n",
    "    tab_percent = tab_percent.round(2).astype(float)\n",
    "    #Creating output tab by combining the count and proportion together using pd.concat()\n",
    "    output_tab = pd.concat([tab_count, tab_percent], axis=1).reset_index()\n",
    "    #Naming the three columns \n",
    "    output_tab.columns = ['variable name', 'count', 'proportion']\n",
    "    return missing_num, output_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test your written functions with a real dataset. (3')\n",
    "\n",
    "<font size='4'>\n",
    "    \n",
    "**Test the summary function for the continuous measure** (1')\n",
    "- Load the `PTSD dataset.xlsx` and name it as `ptsd_df`.\n",
    "    - The dataset should be stored under `data` folder when you sync changes and fetch origins the GitHub repository.\n",
    "- Use the column `pcl5month_score.baseline` as the input vector. This is a continuous measure.\n",
    "- Extract the corresponding column and give it a name `pcl5month_base`.\n",
    "- (*Optional*) You convert from a pandas.dataframe to an numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ptsd dataset in this code section only (no point for this part as you have done it a few times)\n",
    "ptsd_df = pd.read_excel(\"data/PTSD dataset.xlsx\", sheet_name=1)\n",
    "pcl5month_base = ptsd_df['pcl5month_score.baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[51.0, 42.0, 62.0]\n"
     ]
    }
   ],
   "source": [
    "# test continuous measure\n",
    "missing_num_cont, output_ls_cont = fn_marginal_continuous(pcl5month_base)\n",
    "print(missing_num_cont)\n",
    "print(output_ls_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Test the summary function for the categorical measure** (2')\n",
    "\n",
    "- Use the column `mdd_code` as the input vector. This is a binary vector.\n",
    "1. Extract the corresponding column and give it a name `mdd_code_vec`. Output your results as `missing_num_1` and `tab_1`. Print each element out (You will write `print()` twice).\n",
    "2. Create a copy of `mdd_code_vec` and name it as `mdd_code_vec_2`. Change its first element to `NaN`.\n",
    "    - Rerun the `fn_marginal_categorical()` with the new vector. Output your results as `missing_num_2` and `tab_2`. Print each element out (You will write `print()` twice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "   variable name  count  proportion\n",
      "0              0    340       70.39\n",
      "1              1    143       29.61\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 1 only:\n",
    "#Extracting the corresponding column and giving it a name mdd_code_vec\n",
    "mdd_code_vec = ptsd_df['mdd_code']\n",
    "missing_num_1, tab_1 = fn_marginal_categorical(mdd_code_vec)\n",
    "#Outputing results as missing_num_1 and tab_1\n",
    "print(missing_num_1)\n",
    "print(tab_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "   variable name  count  proportion\n",
      "0            0.0    339       70.33\n",
      "1            1.0    143       29.67\n"
     ]
    }
   ],
   "source": [
    "# Write your own code for scenario 2 only:\n",
    "#Extracting the corresponding column and giving it a name mdd_code_vec_2\n",
    "mdd_code_vec_2 = mdd_code_vec.copy()\n",
    "#Changing first element to NaN\n",
    "mdd_code_vec_2.iloc[0] = np.nan\n",
    "missing_num_2, tab_2 = fn_marginal_categorical(mdd_code_vec_2)\n",
    "#Outputing results as missing_num_2 and tab_2\n",
    "print(missing_num_2)\n",
    "print(tab_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lambda functions and for loop (2')\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "- Create a ``` lambda ``` function that checks if column `pcl5_score_intake` is greater than 30, denoted as `fn_pcl5_ptsd_check`.\n",
    "- Create a new list `pcl5_score_intake_ls` that shows `True` if `pcl5_score_intake`>30 and `False` otherwise using a for loop.\n",
    "    - You can also try `map()` function to iterate the function over `pcl5_score_intake`.\n",
    "    - Syntax is simple: `map(function_name, iterable, ...)`. \n",
    "- Print out the number of patients with `pcl5_score_intake` over 30 and mark them as **Clinically Significant for PTSD**.\n",
    "    - Your output can be something like `XXX out of YYY patients (ZZZ%) were marked as clinically significant for PTSD.`\n",
    "    - Round your percentage with no more than **2** decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 out of 483 patients (93.37%) were marked as clinically significant for PTSD.\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "pcl5_score_intake_col = ptsd_df['pcl5_score_intake'].to_numpy()\n",
    "#Creating lambda function that checks if column pcl5_score_intake is greater than 30\n",
    "fn_pcl5_ptsd_check = lambda pcl5_score_intake : pcl5_score_intake > 30\n",
    "pcl5_score_intake_ls = []\n",
    "#Creating a new list pcl5_score_intake_ls that shows True if pcl5_score_intake>30 and False otherwise using a for loop\n",
    "for pcl5_score_intake in pcl5_score_intake_col:\n",
    "    high_pc15 = fn_pcl5_ptsd_check(pcl5_score_intake)\n",
    "    pcl5_score_intake_ls.append(high_pc15)\n",
    "#Creating num significant and total patients variables     \n",
    "num_significant = sum(pcl5_score_intake_ls)\n",
    "total_patients = len(pcl5_score_intake_ls)\n",
    "#Rounding by 2 decimal places \n",
    "percent_significant = round((num_significant / total_patients) * 100, 2)\n",
    "#Printing out the number of patients with pcl5_score_intake over 30 and mark them as Clinically Significant for PTSD\n",
    "print(f\"{num_significant} out of {total_patients} patients ({percent_significant}%) were marked as clinically significant for PTSD.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
